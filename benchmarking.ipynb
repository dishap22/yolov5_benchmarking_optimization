{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torchinfo import summary\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "import torch.profiler\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "from torch.quantization import quantize_dynamic\n",
    "import onnx\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "current_dir = os.path.basename(os.getcwd())\n",
    "\n",
    "if current_dir != \"yolov5\":\n",
    "    if os.path.isdir(\"yolov5\"):\n",
    "        os.chdir(\"yolov5\")\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.torch_utils import select_device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load COCO 128 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 100\n"
     ]
    }
   ],
   "source": [
    "data_path  = Path(\"../datasets/coco128/images/train2017\")\n",
    "image_files = list(data_path.glob(\"*.jpg\"))[:100]\n",
    "print(f\"Total images: {len(image_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load YOLOv5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ v7.0-411-gf4d8a84c Python-3.11.11 torch-2.6.0+cu124 CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients, 48.9 GFLOPs\n",
      "Fusing layers... \n",
      "YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients, 109.0 GFLOPs\n",
      "Fusing layers... \n",
      "YOLOv5x summary: 444 layers, 86705005 parameters, 0 gradients, 205.5 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "device = select_device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "models  = {\n",
    "    'yolov5n': DetectMultiBackend('yolov5n.pt', device=device),\n",
    "    'yolov5s': DetectMultiBackend('yolov5s.pt', device=device),\n",
    "    'yolov5m': DetectMultiBackend('yolov5m.pt', device=device),\n",
    "    'yolov5l': DetectMultiBackend('yolov5l.pt', device=device),\n",
    "    'yolov5x': DetectMultiBackend('yolov5x.pt', device=device),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Inference and Benchmark Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running yolov5n ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::silu_ encountered 57 time(s)\n",
      "Unsupported operator aten::add encountered 10 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::mul encountered 22 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 3 time(s)\n",
      "Unsupported operator aten::pow encountered 3 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running yolov5s ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::silu_ encountered 57 time(s)\n",
      "Unsupported operator aten::add encountered 10 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::mul encountered 22 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 3 time(s)\n",
      "Unsupported operator aten::pow encountered 3 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running yolov5m ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::silu_ encountered 79 time(s)\n",
      "Unsupported operator aten::add encountered 17 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::mul encountered 22 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 3 time(s)\n",
      "Unsupported operator aten::pow encountered 3 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running yolov5l ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::silu_ encountered 101 time(s)\n",
      "Unsupported operator aten::add encountered 24 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::mul encountered 22 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 3 time(s)\n",
      "Unsupported operator aten::pow encountered 3 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running yolov5x ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::silu_ encountered 123 time(s)\n",
      "Unsupported operator aten::add encountered 31 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::mul encountered 22 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 3 time(s)\n",
      "Unsupported operator aten::pow encountered 3 time(s)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((640, 640))\n",
    "])\n",
    "\n",
    "\n",
    "latencies = {}\n",
    "fps_values = {}\n",
    "gflops_dict = {}\n",
    "params_dict = {}\n",
    "utilization_dict = {}\n",
    "model_size_dict = {}\n",
    "per_layer_gflops_dict = {}\n",
    "oi_dict = {}\n",
    "bound_type_dict = {}\n",
    "timing_results = []\n",
    "profile_outputs = {}\n",
    "profiler_tables = {}\n",
    "\n",
    "PEAK_GFLOPS = 410 # GFLOPS\n",
    "PEAK_BANDWIDTH = 28.1 # GB/s\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n--- Running {model_name} ---\")\n",
    "    model = model.to(device).eval()\n",
    "    dummy = torch.randn(1, 3, 640, 640).to(device)\n",
    "    for _ in range(3):\n",
    "        with torch.no_grad():\n",
    "            _ = model(dummy)\n",
    "\n",
    "    def profile_model_inference(model, image_files, transform, device):\n",
    "        total_time = 0\n",
    "        with torch.profiler.profile(\n",
    "            activities=[\n",
    "                torch.profiler.ProfilerActivity.CPU\n",
    "            ],\n",
    "            record_shapes=True,\n",
    "            profile_memory=True,\n",
    "            with_stack=False\n",
    "        ) as prof:\n",
    "\n",
    "            for img_path in image_files:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "                start_time = time.time()\n",
    "                with torch.no_grad():\n",
    "                    _ = model(img)\n",
    "                end_time = time.time()\n",
    "\n",
    "                total_time += (end_time - start_time)\n",
    "\n",
    "                prof.step()  # Mark end of one iteration\n",
    "\n",
    "        return total_time, prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)\n",
    "\n",
    "    # cProfile for profiling\n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()\n",
    "    total_time, prof_table = profile_model_inference(model, image_files, transform, device)\n",
    "    pr.disable()\n",
    "\n",
    "    s = io.StringIO()\n",
    "    ps = pstats.Stats(pr, stream=s).strip_dirs().sort_stats('tottime')\n",
    "    ps.print_stats(15)\n",
    "\n",
    "    profile_outputs[model_name] = s.getvalue()\n",
    "\n",
    "    # pytorch profiler\n",
    "    profiler_tables[model_name] = prof_table\n",
    "\n",
    "    avg_latency = (total_time / len(image_files)) * 1000  # Convert to ms\n",
    "    avg_fps = len(image_files) / total_time  # Compute FPS\n",
    "\n",
    "    latencies[model_name] = avg_latency\n",
    "    fps_values[model_name] = avg_fps\n",
    "    timing_results.append((model_name, avg_latency, avg_fps))\n",
    "\n",
    "    # model parameters\n",
    "    info = summary(model, input_size=(1, 3, 640, 640), verbose=0)\n",
    "    total_params = info.total_params\n",
    "    params_m = total_params / 1e6\n",
    "    model_size_mb = total_params * 4 / (1024 ** 2)\n",
    "\n",
    "    params_dict[model_name] = params_m\n",
    "    model_size_dict[model_name] = model_size_mb\n",
    "\n",
    "    # FLOPs\n",
    "    input_tensor = torch.randn(1, 3, 640, 640).to(device)\n",
    "    flops = FlopCountAnalysis(model, input_tensor)\n",
    "    total_flops = flops.total()\n",
    "    gflops = total_flops / 1e9\n",
    "    gflops_dict[model_name] = gflops\n",
    "\n",
    "\n",
    "    # Utilization\n",
    "    actual_gflops_per_second = gflops / (avg_latency / 1000)\n",
    "    utilization = (actual_gflops_per_second / PEAK_GFLOPS) * 100\n",
    "    utilization_dict[model_name] = utilization\n",
    "\n",
    "    # Operational Intensity\n",
    "    input_size_bytes = 3 * 640 * 640 * 4  # RGB image, float32\n",
    "    activation_estimate = input_size_bytes * 3\n",
    "    memory_accessed = total_params * 4 + activation_estimate\n",
    "    oi = total_flops / memory_accessed\n",
    "    peak_oi = PEAK_GFLOPS / PEAK_BANDWIDTH\n",
    "\n",
    "    oi_dict[model_name] = oi\n",
    "    bound_type = \"Compute Bound\" if oi > peak_oi else \"Memory Bound\"\n",
    "    bound_type_dict[model_name] = bound_type\n",
    "\n",
    "    # Per-layer GFLOPs\n",
    "    layer_flops = flops.by_module()\n",
    "    layer_gflops = {k: v / 1e9 for k, v in layer_flops.items()}\n",
    "    per_layer_gflops_dict[model_name] = layer_gflops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________\n",
      "Model                  Latency (ms)        FPS\n",
      "_______________________________________________\n",
      "yolov5n                   31.21 ms       32.04\n",
      "yolov5s                   59.64 ms       16.77\n",
      "yolov5m                  125.90 ms        7.94\n",
      "yolov5l                  243.12 ms        4.11\n",
      "yolov5x                  429.80 ms        2.33\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"_______________________________________________\")\n",
    "print(\"Model                  Latency (ms)        FPS\")\n",
    "print(\"_______________________________________________\")\n",
    "for model_name, latency, fps in timing_results:\n",
    "    print(f\"{model_name:<16} {latency:>14.2f} ms    {fps:>8.2f}\")\n",
    "print(\"_______________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1YAAAHYCAYAAABOeXnqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQoxJREFUeJzt3XucjeX+//H3GsyM05wYxzDYGbYwYdOgkIxG5FSEQs47lCaVIip7O+wSItlbDhHN5FgOw2SSUlHszhjtQuOQQzPWOA5jrt8f/WZ9LbNolnuNNbO8no/HetTc97Wu9bnvrsZ6u+77um3GGCMAAAAAwHXz83YBAAAAAFDYEawAAAAAwCKCFQAAAABYRLACAAAAAIsIVgAAAABgEcEKAAAAACwiWAEAAACARQQrAAAAALCIYAUAAAAAFhGsAAC4Di+++KJsNpv2799/Xe//+OOPZbPZtHDhQo/WBQDwDoIVAHjJI488IpvNpjVr1rjcn5GRoerVqys8PFxHjx51bN+4caO6dOmiihUryt/fX+Hh4WrXrp3i4+NljMnVT04A2Lp165/WZIxRQkKC7r33XoWHh8vf318VK1ZU586dtWHDhus/2CtqcfV64IEH8tTH/v37He9p2bLlVdvdddddjnYHDx60XLs35YSwf/zjHx7td/r06QQ7APCQot4uAABuVrNmzdKWLVs0cOBAff/99ypXrpzT/scff1z79+/XypUrVb58eWVnZ2vo0KGaO3euatasqcGDB6tatWo6evSoli1bpp49e2rp0qVKSEhQ8eLF3a7n3Llz6tGjh9asWaMGDRroySefVIUKFZSamqolS5YoNjZWgwYN0pw5c+TnZ+3v5aZNm6ayZcs6batWrZpbfQQGBuqTTz7RTz/9pFtvvdVp3969e/Xpp58qMDBQ58+ft1SrL5s+fboiIiLUr18/b5cCAIUewQoAvCQ4OFgLFy7UPffcowEDBjjNXK1atUpvv/22+vXrpy5dukiS/vGPf2ju3Lnq2rWrli5dqoCAAEf70aNHa9SoUXrttdc0fPhwzZs3z+16hg0bpjVr1ujxxx/XtGnTnMLTc889p0ceeURz585VlSpV9MILL1g4cqlz586KiIiw1Ef79u21fv16zZ8/X5MmTXLa99Zbb6lEiRJq166dVq1aZelzAADICy4FBAAvuvvuuzVy5EitXbtWc+bMkST99ttvGjx4sCIiIvT6669Lkk6cOKHJkyercuXKWrRokVOokiSbzaZXXnlFjRo10oIFC/Tjjz+6VccPP/yghQsXqmHDhrlClST5+/trwYIFqly5siZPnqwTJ05Ikh5++GEVKVJEqampufo8e/asgoODdeedd7r8zFOnTunixYtu1Xm50NBQde3aVW+//bYuXbrk2H7x4kUtWrRIDz74oIKCgly+99ChQxo4cKAqV64sf39/3XLLLRo8eLCOHDniss4nnnhCFStWVPHixdWwYUMtW7bsqnUdPXpUI0aMUEREhPz9/VW+fHk9/PDD130vljuys7M1ceJEtWrVynGpaOXKldW3b1/9+uuvjnY5l1MeOHBAW7Zscbok8/I6f/75Z/Xr10+VKlVynKfHHnvM8d8/R84lnnv37tW4ceNUrVo1BQQEqE6dOlqyZInLWr/77jv17NnT0XflypXVqVMn7dy5U5I0fPhw2Ww27dq1K9d7L1y4oPDwcDVu3NgDZw0APINgBQBeNmnSJNWtW1dPPfWUUlJSNGDAAKWlpWnRokUqXbq0JGndunU6d+6cHnnkEZUsWdJlP35+fho8eLCMMVqxYoVbNaxYsULGGA0ePPiql/mVKFFCffr00dmzZ7V+/XpJUr9+/ZSdna1Fixblar9y5UplZGS4vMysQYMGCgoKUkBAgBo0aKC33nrLrXpzDBw4UEeOHHHUI0lr1qzR0aNHNXDgQJfvOXTokP72t79p4cKF6tixo2bMmKEOHTpo3rx5atq0qdP9bFlZWYqNjdXrr7+u6Ohovfrqq2rbtq369+/v8t641NRUNW7cWO+8844eeOABzZo1S0OHDlVSUpKaNGniFG7yw4ULFzRlyhRVr15dcXFxmjVrlrp06aJly5apWbNmSktLkySFh4dr8eLFKlu2rGrXrq3Fixc7XuHh4ZKkb775Ro0aNVJSUpL69++vN954Q7169dLixYvVvHlz2e32XJ/ft29fbdq0SY8//rgmT56srKwsPfzww9q2bZtTu8TERDVp0kTr1q1Tjx49NHPmTA0bNkznz5/X559/LkkaMmSIJLkcG6tWrdKJEyc0ePBgj54/ALDEAAC87uuvvzb+/v4mPDzcSDLPPPOM0/6nnnrKSDIrVqy4Zj87duwwkky3bt0c28aPH28kmU8//fSq7+vWrZuRZHbu3HnN/pcvX24kmaeeesoYY8ylS5dM1apVza233pqrbZs2bUyJEiVMRkaGY9u0adNM//79zfz5880HH3xgXn/9dVO3bl0jyTz22GPX/Owc+/btM5LMgAEDTHZ2tqlZs6bp1KmTY39sbKyJjIw0xhjTt29fI8mkpqY69j/yyCNGklmyZIlTv2+//baj3xzz5s0zkswTTzzh1Pbzzz83NpvNSDL79u1zbO/cubMJDQ01P//8c66aS5UqZfr16+fYtnnzZiPJLFiw4E+POafthAkTrtkuOzvbnDlzJtf2Dz/80Egy//rXv5y2V6tWzbRs2dJlX1FRUaZ69erm999/d9q+fft2U6RIEfPiiy86tuWMsdjYWHPp0iXH9l9//dUUK1bM9OzZ07HtzJkzJjw83AQHB+c6T8YYp/c3a9bMlClTxpw/f96pTZs2bUypUqXMqVOnXNYOAN7AjBUAFABRUVEaP368jh8/rrp162rChAlO+3NmB4KDg6/ZT85+V7MJ13K9/fv5+alPnz766aef9NlnnznapaamavPmzerWrZtj1k2SRo4cqXnz5unRRx9Vx44dNWLECH3zzTdq3ry5Zs+enWtm48/YbDb1799f69at09GjR3Xw4EFt3LhRAwYMcNk+Oztbq1evVmRkpHr16uW075FHHlHNmjW1cuVKx+qKOTN/zz//vFPb6OhotWnTxmmb3W7XBx98oPbt2ysoKEgnTpxwvEqVKqU77rhDGzdudOv43GWz2VSiRAlJfxzryZMndeLECUVFRSk4OFjbt2/PUz8//PCDvvnmGz300EPKzs52OpYaNWroL3/5i8tjefLJJ51mPKtUqaLIyEjt3bvXsS0pKUnHjx/XyJEjVaNGjVx9XP7+oUOH6vfff3e6T+6XX37RRx99pJ49e6pUqVJ5Oh4AuBEIVgBQQDRr1kyS1LhxY/n7+zvty7lX6M8CU14D0pWs9J9zqd/ly3a//fbbys7OztNqc0WLFtXYsWMlSWvXrnWj6v/7fGOM3n77bc2fP19FihRRnz59XLY9fvy4Tp06pdtuuy3XPpvNprp16yo9PV3p6emS/rjHqGzZsrlWbJSkunXrOv28d+9eZWdna8mSJQoPD8/12rRpk9Nlhvll9erVatasmYoXL67Q0FDH59vtdselgH9m9+7dkv64TNXVsaSkpLg8FldBqUyZMvr9998dP+eErIYNG/5pHQ8++KDKlCmjuXPnOra99dZbjstWAaAgYVVAACgE6tWrJ0nasWOHunbtetV2OTf+169f3+3+V65cqR07dlzzC6+r/mvWrKk777xT7733nl5//XUVL15cixYtUkREhFq3bp2nz69evbok6dixY27VLUmVKlVSbGys5s2bpwsXLqhDhw4qX7682/1YlZ2dLUnq3r27Bg0adMM/X5Lef/99denSRY0bN9Zrr72mqlWrOpbez5l9youcdiNGjND999/vso2rJf2LFCnisq1x8Xy1vAgMDFTfvn01bdo0/fzzz6pWrZoWLFighg0bsnAFgAKHYAUAhcB9993nCCxjx451XO51uezsbM2dO1c2m03dunVzq/9u3brppZde0n/+8x8NHDjQ5QIWZ8+e1eLFi1WiRAm1b9/eaV+/fv00YMAArVq1StWqVdNPP/2kcePGyWaz5enzc2YxKlSo4FbdOQYMGOBYln7WrFlXbRceHq7SpUu7XDXRGKMff/xRoaGhCg0NlfRHaExJSdGxY8dyzVpd2cdf/vIX+fn56dy5c7rnnnuu6zisevvttxUYGKgtW7Y4jZEzZ844ZuEud7X/PrVq1XL8u6ePJafvr7/++qqh7XJDhgzRa6+9prfeektNmzbVb7/9phdffNGjNQGAJ3ApIAAUAuHh4Xr66ad16NAhPfroo7pw4YLTfmOMRo8erR07dujRRx/NdZnan6lXr5769OmjnTt3atSoUblmGC5evKiBAwfq4MGDGj16dK6H+3bv3l0lS5bUwoULtXDhQtlstlyXAWZlZbm81PDs2bMaP368JKlTp05u1Z2jQ4cOeumll/Tyyy/r3nvvvWo7Pz8/de7cWXv27NHy5cud9i1ZskQ///yzunbt6ggcObODEydOdGr7xRdfKDk52WlbmTJl1L59e61bt06bN292+fn5fSlgkSJFZLPZcs1MTZgwweVsValSpVxeHhgVFaV69epp3rx5jssCL2eM0fHjx6+rxpiYGIWHh2v69Okul6C/ss5atWqpdevWWrhwod58802VKlUq1/1xAFAQMGMFAIXE+PHjdfDgQc2fP1///e9/1bt3b1WrVk3Hjh3TsmXLtHPnTnXo0OGqMzaLFi3Sxx9/nGt71apV1adPH7355ps6ceKEpk2bps2bN6t79+6qUKGCUlNTtWTJEu3du1eDBg3SmDFjcvVRqlQpdevWTe+8845KlCihu+66y3F5X47Tp08rIiJC999/v+rUqaPw8HAdOHBACxcu1MGDB/Xss8+qUaNG13VuihYtqnHjxuWp7cSJE7Vp0yb17NlTmzdvVr169fTtt986Hn78z3/+09G2b9++mjdvnmbMmKHU1FS1adNGv/76q9544w3dfvvt+u9//+vU95w5c9SiRQu1bdtWvXr10t/+9jf5+fnpwIEDWr9+vRo3bux0L5q7tmzZctV9Y8aM0YMPPqjly5erZcuWjnvPNm7cqF27duUKw5J0xx13aN68eXrhhRdUp04d+fn5qWPHjipZsqTeeecd3X333WrYsKH69eunevXq6eLFi9q/f79Wr16tvn37XtfMUYkSJbRgwQJ17dpVDRo00IABA1S7dm2lp6dry5Ytio2N1YgRI5zeM3ToUPXo0UO//fabBg4c6LQgCgAUGF5bjxAA4CRnSe2+fftes926detMp06dTPny5U2xYsVMmTJlTNu2bc3SpUtNdnZ2rvY5S2Ff7dW8eXNH20uXLpmlS5eatm3bmjJlyphixYqZcuXKmfvvv9+sX78+T/XrKkuInz9/3gwcONDUr1/fhIaGmiJFipgyZcqYmJgYs3r16jydI2Ocl1v/M66WWzfGmNTUVDNgwABTsWJFU7RoUVOpUiUzaNAgc/jw4Vx92O12M3z4cFO+fHkTEBBgoqKizHvvvec4r5cvt26MMWlpaWb06NGmdu3aJiAgwJQuXdrUrl3bDBo0yGzbts3R7nqWW7/W6+LFi8aYP5aIv+2220xgYKAJDw83vXr1MqmpqS6XVj969Kjp2rWrCQ0Ndbl8fGpqqhk2bJipUaOG8ff3NyEhIaZevXrmiSeeMD/++KOj3dXOhTHGtGzZ0lSrVi3X9p07d5pu3bqZ8PBwU6xYMVOpUiXTpUsXl0v+X7hwwZQvX95IMl9++eWfni8A8AabMdd5RykAAMANcOnSJVWrVk3lypXLNUsIAAUF91gBAIACbcWKFTp06JCGDh3q7VIA4KqYsQIAAAXSmjVrlJqaqgkTJqhYsWLau3evAgMDvV0WALhEsAIAAAVSRESEDh8+rAYNGujNN9/k2VUACjSCFQAAAABYxD1WAAAAAGARwQoAAAAALOIBwVfIzs7W4cOHVbp0adlsNm+XAwAAAMBLjDE6deqUKlWqJD+/a89JEayucPjwYVWpUsXbZQAAAAAoIFJTU3XLLbdcsw3B6gqlS5eW9MfJCwoK8nI1AAAAALwlIyNDVapUcWSEayFYXSHn8r+goCCCFQAAAIA83SLE4hUAAAAAYBHBCgAAAAAsIlgBAAAAgEUEKwAAAACwiGAFAAAAABYRrAAAAADAIoIVAAAAAFhEsAIAAAAAiwhWAAAAAGARwQoAAAAALCJYAQAAAIBFBCsAAAAAsIhgBQAAAAAWEawAAAAAwCKCFQAAAABYVNTbBQAAAABW2GzergCeZoy3K3AfM1YAAAAAYBHBCgAAAAAsIlgBAAAAgEUEKwAAAACwiGAFAAAAABYRrAAAAADAIoIVAAAAAFhEsAIAAAAAiwhWAAAAAGARwQoAAAAALCJYAQAAAIBFBCsAAAAAsIhgBQAAAAAWEawAAAAAwCKCFQAAAABYRLACAAAAAIsIVgAAAABgEcEKAAAAACwiWAEAAACARQUqWJ0+fVq33HKLbDabduzY4bRv3rx5qlWrlgIDA9WgQQOtXbs21/vtdrsGDBigsLAwlS5dWg888ICOHDlyo8oHAAAAcJMqUMFqwoQJysrKyrU9Pj5egwYNUo8ePZSYmKjo6Gh16dJF27Ztc2rXo0cPJSUlac6cOVqyZIlSUlIUGxvrsk8AAAAA8BSbMcZ4uwhJ2rNnjxo3bqypU6dq6NCh+uqrr9S4cWNJUmRkpBo1aqSlS5c62jdr1kwhISFav369JOmLL75Qs2bNtHHjRsXExEiSUlJSVKdOHcXHx6t79+55qiMjI0PBwcGy2+0KCgry8FECAADA02w2b1cATysYCcW9bFBgZqxGjBihoUOHKjIy0mn7L7/8or179+YKRg899JCSk5OVmZkpSUpMTFRISIjatm3raBMZGamoqChH+AIAAACA/FAggtXy5cv1/fffa9y4cbn27dmzR5JUu3Ztp+116tTRhQsXtG/fPke7yMhI2a74K4s6deo4+nAlMzNTGRkZTi8AAAAAcIfXg9XZs2cVFxeniRMnupxeS09PlySFhIQ4bQ8NDZUkpaWlOdpd2SanXU4bVyZNmqTg4GDHq0qVKtd5JAAAAABuVl4PVv/4xz9Uvnx5Pfroo175/Oeee052u93xSk1N9UodAAAAAAqvot788AMHDmjq1KlatWqV7Ha7pD+WXM/55+nTpx0zU3a7XRUqVHC8N2cmKywsTNIfM1OuQlF6erqjjSsBAQEKCAjwzAEBAAAAuCl5dcZq3759unDhgu677z6FhoYqNDRUHTt2lCS1bt1a99xzj+Peqivvk9qzZ4/8/f1Vo0YNSX/cg5WSkqIrFzncs2dPrvuzAAAAAMCTvBqsoqKitHnzZqfXtGnTJElz5szR7NmzVaNGDdWqVUvLli1zem9CQoLatGkjf39/SVJsbKzS09OVnJzsaLN37159/fXXat++/Y07KAAAAAA3Ha9eChgSEqJWrVq53NeoUSM1bNhQkvTiiy+qd+/eqlmzplq3bq2EhARt375dn3zyiaN9dHS02rVrp/79+2vq1KkKDAzUmDFjVL9+fXXt2vVGHA4AAACAm5RXg1Ve9ezZU2fPntXkyZM1efJkRUZGatWqVYqOjnZql5CQoLi4OA0ePFhZWVmKiYnRzJkzVbRooThMAAAAAIWUzVx5U9JNzp2nKwMAAMD7rniMKXxAQUko7mQDry+3DgAAAACFHcEKAAAAACwiWAEAAACARQQrAAAAALCIYAUAAAAAFhGsAAAAAMAighUAAAAAWESwAgAAAACLCFYAAAAAYBHBCgAAAAAsIlgBAAAAgEUEKwAAAACwiGAFAAAAABYRrAAAAADAIoIVAAAAAFhEsAIAAAAAiwhWAAAAAGARwQoAAAAALCJYAQAAAIBFBCsAAAAAsIhgBQAAAAAWEawAAAAAwCKCFQAAAABYRLACAAAAAIsIVgAAAABgEcEKAAAAACwiWAEAAACARQQrAAAAALCIYAUAAAAAFhGsAAAAAMAighUAAAAAWESwAgAAAACLCFYAAAAAYBHBCgAAAAAsIlgBAAAAgEUEKwAAAACwiGAFAAAAABYRrAAAAADAIoIVAAAAAFhEsAIAAAAAiwhWAAAAAGARwQoAAAAALCJYAQAAAIBFBCsAAAAAsIhgBQAAAAAWEawAAAAAwCKCFQAAAABYRLACAAAAAIsIVgAAAABgEcEKAAAAACwiWAEAAACARQQrAAAAALCIYAUAAAAAFhGsAAAAAMAighUAAAAAWESwAgAAAACLCFYAAAAAYBHBCgAAAAAsIlgBAAAAgEUEKwAAAACwiGAFAAAAABYRrAAAAADAIoIVAAAAAFhEsAIAAAAAiwhWAAAAAGARwQoAAAAALCJYAQAAAIBFBCsAAAAAsIhgBQAAAAAWEawAAAAAwCKCFQAAAABYRLACAAAAAIu8HqzWr1+vli1bKjw8XAEBAapRo4bi4uJkt9ud2q1Zs0YNGjRQYGCgatWqpQULFuTq68KFC3r66adVoUIFlSxZUm3btlVKSsqNOhQAAAAANymvB6u0tDQ1bdpUc+bM0caNGxUXF6dFixbpwQcfdLTZunWrunTpoujoaCUmJqpHjx4aMGCAli9f7tTX448/rrlz52rixIlauXKlMjMz1aZNm1whDQAAAAA8yWaMMd4u4kpz587V4MGDdejQIVWqVEnt2rXT6dOn9dlnnzna9OrVS99884127dolSTp48KAiIiI0e/ZsDR48WNIfoa1q1aoaN26cnnnmmTx9dkZGhoKDg2W32xUUFOT5gwMAAIBH2WzergCeVlASijvZwOszVq6UKVNG0h+X9mVmZmrz5s1OM1iS9NBDD2n37t3av3+/JCkpKUnZ2dlO7cLCwhQTE6P169ffsNoBAAAA3HwKTLC6dOmSzp8/r//+9796+eWXdf/99ysiIkI///yzLl68qNq1azu1r1OnjiRpz549jn+WK1dOoaGhudrltAEAAACA/FDU2wXkqFatmg4dOiRJuvfee7V06VJJUnp6uiQpJCTEqX1OgEpLS3O0u7JNTrucNq5kZmYqMzPT8XNGRsZ1HwMAAACAm1OBmbFav369Pv/8c82dO1e7d+9Wx44ddenSpXz/3EmTJik4ONjxqlKlSr5/JgAAAADfUmBmrOrXry9Jio6O1t/+9jdFRUVp1apV+utf/ypJuVb2y5nJCgsLk/THzJSr1f/S09MdbVx57rnnFBcX5/g5IyODcAUAAADALQVmxupy9evXV7FixfS///1PNWvWVLFixXLdJ5Xzc869V7Vr19bRo0cdgevydlfen3W5gIAABQUFOb0AAAAAwB0FMlht375dFy9eVI0aNRQQEKDWrVvnemZVQkKC6tSpo4iICElSTEyM/Pz8tGLFCkeb9PR0JSUlqX379jeyfAAAAAA3Ga9fCti1a1c1btxY9evXV/HixfXtt9/qlVdeUf369dW5c2dJ0gsvvKBWrVrpscceU/fu3bV582YtXbpUCQkJjn5uueUWDRw4UE8//bSKFCmiypUra+LEiQoODtaQIUO8dHQAAAAAbgZeD1ZNmjRRQkKCJk+erOzsbEVERGjQoEEaNWqU/P39JUktWrTQypUrNXbsWM2bN09Vq1bVW2+9levZVjNmzFCpUqU0evRonTp1Ss2bN9emTZsUHBzsjUMDAAAAcJOwGVNQnmtcMLjzdGUAAAB4n83m7QrgaQUlobiTDQrkPVYAAAAAUJgQrAAAAADAIoIVAAAAAFhEsAIAAAAAiwhWAAAAAGARwQoAAAAALCJYAQAAAIBFBCsAAAAAsIhgBQAAAAAWFXX3DWlpafr444+1fft2HTlyROfOnVOZMmUUGRmpO++8U40bN86POgEAAACgwMpzsNqyZYtmzJihdevWKSsrS1WrVlXZsmUVEBCg3bt3a+nSpTp9+rQiIiI0YMAAjRgxQkFBQflZOwAAAAAUCHm6FDAmJkadOnVSaGio3n//faWlpWnfvn366quvtHXrVv3www+y2+3atWuXhg8frvfff181atTQ+vXr87t+AAAAAPC6PM1YtWrVSsuWLVNwcPBV29hsNtWuXVu1a9dWXFycPv30U2VkZHisUAAAAAAoqGzGGOPtIgqSjIwMBQcHy263cykjAABAIWCzebsCeFpBSSjuZAOPrAq4f/9+bdq0SWlpaZ7oDgAAAAAKFbeD1VNPPaWRI0c6fl61apUiIyMVExOjW2+9VTt37vRkfQAAAABQ4LkdrFatWuW0pPrzzz+v9u3b67vvvlOTJk00duxYjxYIAAAAAAWd28HqyJEjqlq1qiTp559/VkpKisaOHavbbrtNI0aM0I4dOzxeJAAAAAAUZG4Hq+DgYB07dkyS9OGHHyosLEyNGjWSJAUEBOjcuXOerRAAAAAACrg8PyA4x1133aVx48bp6NGjevXVV9W5c2fHvpSUFMdsFgAAAADcLNyesZo2bZoqVKig0aNHq2rVqvrnP//p2Ld48WLdeeedHi0QAAAAAAo6jz7HKiMjQ4GBgfL39/dUlzccz7ECAAAoXHiOle8pjM+xcvtSwGshiAAAAAC4GV1XsIqPj9eyZcuUmpqq8+fPO+2z2Wz69ttvPVIcAAAAABQGbger559/XpMnT1ajRo1Uq1atQn3ZHwAAAAB4gtvBav78+Xr55Zd5EDAAAAAA/H9urwooSU2bNvV0HQAAAABQaLkdrAYOHKilS5fmRy0AAAAAUCi5vdy6MUZPPPGEdu7cqTZt2igkJMS5Q5tNTz75pCdrvKFYbh0AAKBwYbl131MYl1t3O1glJyera9euOnXqlOsObTZdunTJnS4LFIIVAABA4UKw8j2FMVi5fSngsGHD1LhxY33//ffKzMxUdna206swhyoAAAAAuB5urwqYmpqqmTNnqm7duvlRDwAAAAAUOm7PWLVo0UIpKSn5UQsAAAAAFEpuz1hNnDhRffv2lb+/v+65555ci1dIUlhYmCdqAwAAAIBCwe3FK/z8/m+Sy3aVOwUL831WLF4BAABQuLB4he8pjItXuD1jNX/+/KsGKgAAAAC4GbkdrPr165cPZQAAAABA4eX24hUAAAAAAGd5ClZNmzbV6tWrlZ2dnadOU1NTNWrUKL322muWigMAAACAwiBPlwL26dNHjz32mAYPHqxOnTqpefPmql+/vsLDwxUQEKCTJ09q37592rlzpxITE7Vt2zbdf//9+vvf/57f9QMAAACA1+V5VcBz584pPj5eixYt0ueff66srCyn/cYYVaxYUQ888IAGDhyoevXq5UvB+Y1VAQEAAAoX1lXzPYVxVUC3l1uXpPPnz+ubb77RkSNHdP78eYWFhSkyMlIRERHXW3OBQbACAODG4Muw7/HWl2HGku8pjMHK7VUBJSkwMFB33HHHdRUHAAAAAL6GVQEBAAAAwCKCFQAAAABYRLACAAAAAIsIVgAAAABgkdvB6joWEQQAAAAAn+Z2sKpSpYrGjh2rn3/+OT/qAQAAAIBCx+1g1bt3by1YsEC1atVSq1attHjxYp07dy4/agMAAACAQsHtYDVlyhSlpqZq9erVKlOmjAYOHKiKFStqyJAh+vLLL/OjRgAAAAAo0K5r8Qo/Pz917NhRK1as0KFDhzR+/Hh99tlnio6OVr169TR9+nSdPHnSw6UCAAAAQMFkeVXA3377TampqTp27Jj8/f1VuXJljRs3ThEREfrggw88USMAAAAAFGjXFaxOnTqlf//732ratKkaNGigDz/8UGPHjtXhw4e1YcMGHTx4UJ06ddLjjz/u6XoBAAAAoMAp6u4bHnnkEa1atUqS1KNHD82YMUN33HGHU5ugoCA99thjWrx4sWeqBAAAAIACzO1gtXv3bk2dOlW9evVS6dKlr9qubt262rx5s6XiAAAAAKAwsBme+OskIyNDwcHBstvtCgoK8nY5AAD4LJvN2xXA07z1rZKx5HsKSkJxJxu4fY9VcnKyFixY4HLfwoULmaUCAAAAcNNxO1iNGTNGR48edbnv+PHjGjt2rOWiAAAAAKAwcTtY7dq1S40bN3a5r2HDhvrxxx8tFwUAAAAAhYnbwcpms8lut7vcl56erkuXLlkuCgAAAAAKE7eDVdOmTfXGG2/oyjUvjDGaPXu2mjZt6rHiAAAAAKAwcHu59ZdeekmtW7dW/fr11a9fP1WsWFGHDx/WokWLtHfvXn388cf5UCYAAAAAFFxuB6vo6GglJyfrmWee0bPPPqvs7Gz5+fk5tl/5sGAAAAAA8HVuBytJat68uT777DOdO3dO6enpCgkJUYkSJTxdGwAAAAAUCtcVrHIUL15cxYsX91QtAAAAAFAoXVewSkpK0vLly3Xw4EGdP3/eaZ/NZlNycrJHigMAAACAwsDtYPXKK6/o2WefVUREhOrUqaPg4OD8qAsAAAAACg23g9Ubb7yh4cOH6/XXX8+PegAAAACg0HH7OVZpaWnq3LlzPpQCAAAAAIWT28GqY8eO2rp1a37UAgAAAACFktuXAj766KP6+9//rnPnzqlt27YKCQnJ1aZhw4aeqA0AAAAACgWbMca48wY/P+dJLpvN5vh3Y4xsNpsuXbrkmeq8ICMjQ8HBwbLb7QoKCvJ2OQAA+KzLvkLAR7j3rdJzGEu+x1tj6UruZAO3LwXcvHmz0+ujjz5yvHJ+dseyZcvUqVMn3XLLLSpZsqSioqI0f/58XZn35s2bp1q1aikwMFANGjTQ2rVrc/Vlt9s1YMAAhYWFqXTp0nrggQd05MgRdw8RAAAAANzi9qWALVu29GgBr732miIiIjR16lSFh4frww8/1KBBg5Samqrx48dLkuLj4zVo0CCNGTNGd999txISEtSlSxd9+umnuuOOOxx99ejRQz/++KPmzJmjwMBAjRkzRrGxsdqxY4eKFrX0LGQAAAAAuCq3LwXMsXv3bu3YsUOpqanq37+/KlSooP/9738qX768Spcuned+Tpw4obJlyzptGzx4sBISEpSeni4/Pz9FRkaqUaNGWrp0qaNNs2bNFBISovXr10uSvvjiCzVr1kwbN25UTEyMJCklJUV16tRRfHy8unfvnqd6uBQQAIAbg8u3fA+XAsJTbopLAc+ePatevXrptttuU//+/fXCCy/o8OHDkqTnnntOEyZMcKu/K0OVJN1+++3KyMjQmTNn9Msvv2jv3r25gtFDDz2k5ORkZWZmSpISExMVEhKitm3bOtpERkYqKirKEb4AAAAAID+4HaxGjRqljz76SImJicrIyHC6F6p9+/basGGD5aK2bt2qypUrq3Tp0tqzZ48kqXbt2k5t6tSpowsXLmjfvn2SpD179igyMtJpMY2cdjl9uJKZmamMjAynFwAAAAC4w+1gtXz5ck2ZMkUxMTHy9/d32hcREaH9+/dbKmjr1q2Kj4/XqFGjJEnp6emSlGtZ99DQUEl/PLA4p52rpd9DQ0MdbVyZNGmSgoODHa8qVapYqh8AAADAzcftYHX69GlVrFjR5b4zZ85YKubgwYPq0aOHWrdurccff9xSX3n13HPPyW63O16pqak35HMBAAAA+A63g1X9+vW1YsUKl/vWrVunxo0bX1chJ0+eVGxsrMqUKaMVK1Y4npeVMzNlt9ud2ufMZIWFhTnaXdkmp11OG1cCAgIUFBTk9AIAAAAAd7i9BvkLL7ygTp066ezZs3rwwQdls9n05Zdf6t1339X8+fOva6GIc+fOqUOHDrLb7friiy8UHBzs2Jdzb1XOPVQ59uzZI39/f9WoUcPRbtOmTY6HFF/erl69em7XBAAAAAB55faM1X333af4+Hht3bpVnTt3ljFGjz32mBISErRkyRK1adPGrf6ysrLUvXt37d69Wxs2bFDlypWd9teoUUO1atXSsmXLnLYnJCSoTZs2jvu8YmNjlZ6eruTkZEebvXv36uuvv1b79u3dPUwAAAAAyLPrfo6V9EdwOXHihMLCwnKt2pdXgwcP1ty5czV16lQ1a9bMad/tt9+ugIAAvfvuu+rdu7deeOEFtW7dWgkJCXrrrbf0ySefKDo62tH+3nvv1a5duzR16lTHA4L9/PzcekAwz7ECAODG4NlDvofnWMFTCuNzrNwOVi+//LIGDhyoSpUq5dp35MgRzZ07V+PGjctzfxERETpw4IDLffv27VNERIQkad68eZo8ebJ+/fVXRUZGauLEierQoYNTe7vdrri4OK1cuVJZWVmKiYnRzJkzXdZ6NQQrAABuDL4M+x6CFTzlpghWRYoU0RdffKEmTZrk2rdz5041adJEly5dcq/iAoRgBQDAjcGXYd9DsIKnFMZg5fY9VlcuDnG5I0eOuHyWFAAAAAD4sjzdePTuu+/q3XfflSTZbDY99dRTuQLU+fPntWPHDjVv3tzjRQIAAABAQZanYHXhwgWdOnVK0h8zVmfOnFGRIkWc2vj7+6tPnz565plnPF8lAAAAABRgbt9j1bp1a7355pvXvQpgQcc9VgAA3BjcF+N7uMcKnlIY77Fy+wHBmzdvvu7CAAAAAMAXuR2sJCk7O1sfffSR9u7dq/Pnzzvts9lsevLJJz1SHAAAAAAUBm4Hq99++00tW7bUTz/9JJvNppwrCS9fKZBgBQAAAOBm4vZy63FxcSpbtqxSU1NljNH27du1f/9+TZgwQbfeeqv27t2bH3UCAAAAQIHl9ozVJ598otdff10VK1aU9McqgVWrVtXzzz8vY4yGDx+uxMREjxcKAAAAAAWV2zNWdrtd4eHh8vPzU1BQkI4dO+bYFx0dra1bt3q0QAAAAAAo6NwOVtWrV9eRI0ckSXXr1tXixYsd+1atWqWwsDDPVQcAAAAAhYDblwLed999SkpKUvfu3TV27Fh16tRJ5cqVU7FixfTbb79pypQp+VEnAAAAABRYbj8g+Eo7duzQqlWrdO7cObVt21axsbGeqs0reEAwAAA3Bg919T08IBieUhgfEGw5WF0uNTVVn376qXr16uWpLm84ghUAADcGX4Z9D8EKnlIYg5Xb91hdy5dffqlHHnnEk10CAAAAQIHn0WAFAAAAADcjghUAAAAAWESwAgAAAACLCFYAAAAAYFGenmNVunRp2fKw3EpWVpblggAAAACgsMlTsHrqqafyFKwAAAAA4Gbk0edY+QKeYwUAwI3B39n6Hp5jBU8pKAnFa8+xAgAAAICbEcEKAAAAACwiWAEAAACARQQrAAAAALCIYAUAAAAAFhGsAAAAAMAighUAAAAAWESwAgAAAACLCFYAAAAAYBHBCgAAAAAsIlgBAAAAgEUEKwAAAACwiGAFAAAAABYRrAAAAADAIoIVAAAAAFhEsAIAAAAAiwhWAAAAAGARwQoAAAAALCJYAQAAAIBFBCsAAAAAsIhgBQAAAAAWEawAAAAAwCKCFQAAAABYRLACAAAAAIsIVgAAAABgEcEKAAAAACwiWAEAAACARQQrAAAAALCIYAUAAAAAFhGsAAAAAMAighUAAAAAWESwAgAAAACLCFYAAAAAYFFRbxcAAChcbDZvVwBPM8bbFQBA4ceMFQAAAABYRLACAAAAAIsIVgAAAABgEcEKAAAAACwiWAEAAACARQQrAAAAALCIYAUAAAAAFhGsAAAAAMAighUAAAAAWESwAgAAAACLCFYAAAAAYBHBCgAAAAAsIlgBAAAAgEUEKwAAAACwiGAFAAAAABYRrAAAAADAIq8Hq//9738aOnSooqKiVLRoUd12220u282bN0+1atVSYGCgGjRooLVr1+ZqY7fbNWDAAIWFhal06dJ64IEHdOTIkfw+BAAAAAA3Oa8Hqx9//FHr1q3TX/7yF/31r3912SY+Pl6DBg1Sjx49lJiYqOjoaHXp0kXbtm1zatejRw8lJSVpzpw5WrJkiVJSUhQbG6usrKwbcSgAAAAAblI2Y4zxZgHZ2dny8/sj3/Xr1087duzQDz/84NQmMjJSjRo10tKlSx3bmjVrppCQEK1fv16S9MUXX6hZs2bauHGjYmJiJEkpKSmqU6eO4uPj1b179zzVk5GRoeDgYNntdgUFBXniEAHAp9hs3q4AnuatbwKMJd/DWIKneDeh/B93soHXZ6xyQtXV/PLLL9q7d2+uYPTQQw8pOTlZmZmZkqTExESFhISobdu2jjaRkZGKiopyhC8AAAAAyA9eD1Z/Zs+ePZKk2rVrO22vU6eOLly4oH379jnaRUZGynbFX1nUqVPH0YcrmZmZysjIcHoBAAAAgDsKfLBKT0+XJIWEhDhtDw0NlSSlpaU52l3ZJqddThtXJk2apODgYMerSpUqnikcAAAAwE2jwAer/Pbcc8/Jbrc7Xqmpqd4uCQAAAEAhU9TbBfyZnJkpu92uChUqOLbnzGSFhYU52rkKRenp6Y42rgQEBCggIMCTJQMAAAC4yRT4Gauce6uuvE9qz5498vf3V40aNRztUlJSdOUih3v27Ml1fxYAAAAAeFKBD1Y1atRQrVq1tGzZMqftCQkJatOmjfz9/SVJsbGxSk9PV3JysqPN3r179fXXX6t9+/Y3tGYAAAAANxevXwp49uxZx3LoBw4cUEZGhpYvXy5JatmypcLDw/Xiiy+qd+/eqlmzplq3bq2EhARt375dn3zyiaOf6OhotWvXTv3799fUqVMVGBioMWPGqH79+uratatXjg0AAADAzcHrDwjev3+/qlev7nLf5s2b1apVK0nSvHnzNHnyZP3666+KjIzUxIkT1aFDB6f2drtdcXFxWrlypbKyshQTE6OZM2eqUqVKea6HBwQDwLXxIE7fw0Nd4SmMJXhKYXxAsNeDVUFDsAKAa+MLjO/hyzA8hbEETykoCcWdbFDg77ECAAAAgIKOYAUAAAAAFhGsAAAAAMAighUAAAAAWESwAgAAAACLCFYAAAAAYBHBCgAAAAAsIlgBAAAAgEUEKwAAAACwiGAFAAAAABYRrAAAAADAIoIVAAAAAFhEsAIAAAAAiwhWAAAAAGARwQoAAAAALCJYAQAAAIBFBCsAAAAAsIhgBQAAAAAWEawAAAAAwCKCFQAAAABYRLACAAAAAIsIVgAAAABgEcEKAAAAACwiWAEAAACARQQrAAAAALCIYAUAAAAAFhGsAAAAAMCiot4uAMCNYbN5uwLkB2O8XQEAAJCYsQIAAAAAywhWAAAAAGARwQoAAAAALCJYAQAAAIBFBCsAAAAAsIhgBQAAAAAWEawAAAAAwCKCFQAAAABYRLACAAAAAIsIVgAAAABgEcEKAAAAACwiWAEAAACARQQrAAAAALCIYAUAAAAAFhGsAAAAAMAighUAAAAAWESwAgAAAACLCFYAAAAAYBHBCgAAAAAsIlgBAAAAgEUEKwAAAACwiGAFAAAAABYRrAAAAADAoqLeLgB/zmbzdgXwNGO8XQEAAAA8iRkrAAAAALCIYAUAAAAAFhGsAAAAAMAighUAAAAAWESwAgAAAACLCFYAAAAAYBHBCgAAAAAsIlgBAAAAgEUEKwAAAACwiGAFAAAAABYRrAAAAADAIoIVAAAAAFhEsAIAAAAAiwhWAAAAAGARwQoAAAAALCJYAQAAAIBFBCsAAAAAsIhgBQAAAAAWEawAAAAAwCKCFQAAAABY5HPBas+ePWrbtq1KliypChUq6JlnntGFCxe8XRYAAAAAH1bU2wV4Unp6uu6++27deuutWrlypQ4dOqS4uDidPXtWs2bN8nZ5AAAAAHyUTwWrOXPmKCMjQ6tWrVJYWJgkKSsrS4899pief/55VapUycsVAgAAAPBFPnUpYGJiou655x5HqJKk7t27Kzs7W0lJSV6sDAAAAIAv86lgtWfPHtWuXdtpW0hIiCpWrKg9e/Z4qSoAAAAAvs6nLgVMT09XSEhIru2hoaFKS0tz+Z7MzExlZmY6frbb7ZKkjIyMfKkRkCSGFzyFsQRPYBzBUxhL8JSCMpZyMoEx5k/b+lSwuh6TJk3SSy+9lGt7lSpVvFANbhbBwd6uAL6CsQRPYBzBUxhL8JSCNpZOnTql4D8pyqeCVWhoqGPG6XLp6elO911d7rnnnlNcXJzj5+zsbKWlpalMmTKy2Wz5ViucZWRkqEqVKkpNTVVQUJC3y0EhxliCpzCW4CmMJXgC48g7jDE6depUnhbB86lgVbt27Vz3Utntdh05ciTXvVc5AgICFBAQ4LTN1eWEuDGCgoL4ZQGPYCzBUxhL8BTGEjyBcXTj/dlMVQ6fWrwiNjZWmzZt0smTJx3bli1bJj8/P8XExHivMAAAAAA+zaeC1dChQ1W6dGl17txZSUlJWrBggZ5++mkNHTqUZ1gBAAAAyDc+FaxCQ0OVnJysokWLqnPnzho9erQGDhyo1157zdul4U8EBARo/PjxuS7LBNzFWIKnMJbgKYwleALjqOCzmbysHQgAAAAAuCqfmrECAAAAAG8gWAEAAACARQQrAAAAALCIYIV89fHHH8tms2nHjh0e73vhwoWy2Wy5XqNHj/b4Z8H7GEuwgvGD/FQQxpfNZtOrr77q8c9H/isI4wee4VMPCMbNacOGDU4PbqtcubIXq0FhxliCFYwf5CfGF6xg/NwYBCsUeo0aNVLZsmW9XQZ8AGMJVjB+kJ8YX7CC8XNjcCkgXFqzZo1sNpt++uknp+3p6ekqXry4Zs+eLUlauXKloqKiFBgYqEqVKikuLk7nz5+/Zt/nz59XXFycKlWqpMDAQEVFRWnVqlWO/QsXLlTRokV19OhRp/elpaXJ399f//73v906FpvNpn/961968cUXVb58eZUtW1aPPvqozpw541Y/uD6+NJbmz5+vunXrqnjx4ipTpoxatGihr776yq0+4B5fGj82m01TpkzRmDFjVK5cOYWEhOiZZ56RMUbJycmKiopSqVKl1KZNG6WmprrVN66PL40v3Hi+Mn5Wr14tm82mtWvXOvVTuXJl9ezZM8/9QJIBXMjKyjKVK1c2o0ePdto+a9YsExgYaNLT0837779vbDab6dmzp0lMTDTTpk0zxYsXN926dXO037x5s5FkvvrqK8e2rl27mhIlSphp06aZxMRE07NnT2Oz2cz7779vjDHm5MmTJiAgwMycOdPps//zn/+YYsWKmd9//90YY8yCBQuMJFOuXDnj5+dnqlevbiZOnGiysrKc3ifJVKlSxfTq1cskJiaaGTNmGH9/f/Pss8969JzBNV8ZS1u2bDGSzKhRo8xHH31k1q5da8aNG2eSkpI8fs7wf3xl/Bjzx++iW265xTz88MNmw4YN5qWXXjKSTFxcnKlXr56Jj483K1euNLfccotp27atR88jXPO18fXKK6949Pzg2nxp/PTp08eUL1/eHD9+3BhjTI8ePUylSpVMWlqa507YTYBghasaO3asqVSpktP/fA0bNjS9evUyxhhz++23m+joaKf3/Pvf/zaSzHfffWeMyf3L4ttvvzWSzJw5c5zeFx0dbRo2bOj4uUuXLqZZs2ZObVq3bm3uu+8+x885X0w2bNhgNm7caIYNG2b8/PzMsGHDnN4nyTRp0sRpW9++fU3NmjXdOh+4fr4wll555RUTFhZm5TTgOvnC+DHG9e+iRo0aGZvNZnbt2uXYNnPmTCPJpKen5+n8wBpfGl8EqxvPV8bPyZMnTZUqVUyXLl3M0qVLjSSzYcOG6z0tNy2CFa5q3759xmazmbVr1xpj/u9/9OTkZHPq1Cljs9nM1KlTnd5z8uRJI8nMnj3bGJP7l8WsWbOMJMffpOSYPn26sdls5vTp08YYY9577z1js9nMgQMHjDHGHD582Pj5+Zl33nnnmjWPGjXKFClSxBw+fNixTZIZM2aMU7spU6aYgIAAd08JrpMvjKXk5GQjyfTt29ckJSWZM2fOWDwryCtfGD/GuP5d1LNnT1O5cmWnbRs3bjSSzPfff5+n8wNrfGl8EaxuPF8ZP8b88eeczWYzAQEB5u9///t1npGbG/dY4aoiIiLUtm1bzZs3T9If95dUr15drVu31smTJ2WMUfny5Z3eExwcrICAAKWlpbnsMz09XcWKFVNYWJjT9vLly8sYo5MnT0qSOnTooJIlSyo+Pl6S9N577ykwMFCdO3e+Zs3du3fXpUuX9M033zhtDwkJcfrZ399fmZmZ1+wLnuMLY+nuu+/W4sWL9eOPP6pdu3YqW7as+vTpc9X64Dm+MH5yuPpd5GqbpD+9BwOe4UvjCzeeL42fFi1aqGrVqsrMzNTw4cPzeAZwOYIVrmnQoEFau3atDh06pCVLlujRRx+VzWZTSEiIbDabjh075tTebrcrMzMz1y+DHGFhYbp48aLS09Odth89etTRryQVL15cnTt3dvyyiI+PV8eOHVWyZEnPHyRuCF8YSw8//LC++uorHTt2TDNnztTq1av19NNPu90P3OcL4wcFF+MLVvjK+Bk3bpx+//133XrrrRo2bJiMMdfVz82MYIVr6tSpk0JDQ9WrVy+lpaWpX79+kqRSpUopKipKy5cvd2r/3nvvSfrjbz1cydm+bNkyp+3Lli3T7bff7vTLoGfPnvr666+1ceNGbdu2LU8r08THx6tIkSK6/fbb83yMuDF8aSyVLVtWAwYMUNu2bbV79+4/7QvW+dL4QcHD+IIVvjB+Pv/8c73yyiuaOnWqli5dqq1bt2rGjBl/fvBw5qVLEFGIPP3000aSadeundP2nJVuevfubRITE8306dNNiRIl8rTSTcmSJc306dNNYmKi6d27t7HZbOaDDz5w6v/ChQumTJkyplKlSiYkJMRkZmY67Y+JiTGTJ08269atM+vWrTNDhgwxNpvNjBw50qmdXFx3Pm3aNMPwv/EK81gaN26cGTZsmFm2bJnZsmWLmTVrlilRooQZO3asJ08RrqEwjx9jXP8u6tu3r6lbt67TNle1Iv/54vjCjVOYx8/p06dNzZo1TWxsrGPb+PHjTWBgoNm9e7dHzs/Ngm+W+FOff/65kWQSEhJy7Vu+fLmpX7++8ff3NxUqVDAjR440586dc+x39cvi7NmzZuTIkaZChQrG39/f1K9f36xYscLlZw8ZMsRIMgMGDMi17/HHHze33nqrKV68uAkICDD16tUzM2bMMNnZ2U7tCFYFR2EeS2vWrDFt2rQx4eHhJiAgwNSsWdOMHz/eXLx40copgRsK8/gxhmBV0Pni+MKNU5jHz5AhQ0xYWJjTYhYXL140jRs3No0bN+bPOTfYjOECSlzbuHHjNHv2bB06dEgBAQHeLgeFGGMJVjB+kJ8YX7CC8QNJKurtAlBwpaSkKCUlRTNnztSwYcP4RYHrxliCFYwf5CfGF6xg/OByzFjhqlq1aqVt27bp3nvv1ZIlS1ilCNeNsQQrGD/IT4wvWMH4weUIVgAAAABgEcutAwAAAIBFBCsAAAAAsIhgBQAAAAAWEawAAAAAwCKCFQAAAABYRLACABR6L774omw2mypXrqzs7Oxc+5s3by6bzaZ+/fpZ/qyRI0cqIiLC7fdFRERo+PDhlj8fAFAwEawAAD6hWLFiOnHihD755BOn7QcOHNAXX3yhUqVKeakyAMDNgGAFAPAJ/v7+io2N1bvvvuu0PT4+XnXr1lXNmjW9VBkA4GZAsAIA+IyePXtq+fLlunjxomPb0qVL1atXr1xtP/nkEzVr1kzFixdX2bJl1b9/f6WlpTm1OXz4sO6//36VKFFClStX1r/+9S+Xn3vw4EE9/PDDKlu2rIoXL6677rpLO3fu9OzBAQAKNIIVAMBndOzYUZmZmUpKSpIk7dq1S999950eeughp3Y7d+5U27ZtVbp0aS1btkxTpkzRmjVrFBsbq0uXLjnaderUSV999ZXefPNNzZ49W6tWrdLy5cud+kpPT1eLFi30zTffaObMmVqxYoVKliypu+++W8eOHcv/gwYAFAhFvV0AAACeUqJECXXq1Enx8fG677779O677yo6OlrVq1d3avfPf/5TFSpU0Nq1a1WsWDFJUpUqVdSuXTutX79eHTt21IYNG7Rjxw4lJyfr7rvvliS1atVKVapUUVhYmKOv6dOn6+TJk/ryyy9Vrlw5SVKbNm1Uq1Ytvfrqq1ed5QIA+BZmrAAAPqVnz556//33de7cOcXHx6tnz5652nz66afq1KmTI1RJUkxMjEJCQrR161ZJ0vbt2xUcHOwIVZIUHByse+65x6mvpKQktW7dWmFhYcrKylJWVpaKFCmili1b6quvvsqnowQAFDTMWAEAfEq7du1UrFgxjRs3Tvv27VP37t1ztUlPT1f58uVzbS9fvrzjPqsjR44oPDzcZZvLnThxQtu2bXMKaTlYMAMAbh4EKwCATylWrJi6deum1157TW3atHEZoMLCwlze/3T06FHHZX4VK1bU8ePHXba5sq97771XEyZMyNU2ICDgeg8DAFDIEKwAAD5n4MCBOnbsmAYNGuRyf4sWLbR69WpNnTpVRYv+8Ufhhx9+qJMnT6pFixaSpCZNmshut+ujjz5yXA5ot9u1adMmp3us7rnnHr3zzjuqU6eOSpYsmc9HBgAoqAhWAACf06RJE61evfqq+8eMGaNmzZqpQ4cOGjFihI4eParRo0erSZMmat++vSTp3nvvVcOGDdW7d29NmTJFISEhmjRpkoKCgpz6iouL05IlS9SyZUs98cQTqlq1qo4fP67t27erUqVKevLJJ/PzUAEABQSLVwAAbjqNGjVSUlKSMjIy1K1bNz399NO67777lJiYqCJFikiSbDab3n//fTVq1EhDhgzR0KFDdf/99+uBBx5w6qtMmTLatm2boqKi9OyzzyomJkZPPvmk9u/fr6ZNm3rj8AAAXmAzxhhvFwEAAAAAhRkzVgAAAABgEcEKAAAAACwiWAEAAACARQQrAAAAALCIYAUAAAAAFhGsAAAAAMAighUAAAAAWESwAgAAAACLCFYAAAAAYBHBCgAAAAAsIlgBAAAAgEX/D63HDdTvFwO3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Plot Latency\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(latencies.keys(), latencies.values(), color='blue')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Latency (ms)')\n",
    "plt.title('YOLOv5 Model Latency')\n",
    "plt.show()\n",
    "\n",
    "# Plot FPS\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(fps_values.keys(), fps_values.values(), color='red')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Frames Per Second (FPS)')\n",
    "plt.title('YOLOv5 Model FPS')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/data/coco128.yaml, weights=['yolov5n.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v7.0-411-gf4d8a84c Python-3.11.11 torch-2.6.0+cu124 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/datas\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        128        929      0.629      0.478      0.541       0.35\n",
      "Speed: 0.9ms pre-process, 38.1ms inference, 4.3ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp77\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# For YOLOv5n\n",
    "!python val.py --weights yolov5n.pt --data coco128.yaml --img 640 --iou 0.65 --task val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/data/coco128.yaml, weights=['yolov5s.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v7.0-411-gf4d8a84c Python-3.11.11 torch-2.6.0+cu124 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/datas\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        128        929      0.691      0.623      0.706       0.48\n",
      "Speed: 0.8ms pre-process, 74.9ms inference, 2.2ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp78\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# For YOLOv5s\n",
    "!python val.py --weights yolov5s.pt --data coco128.yaml --img 640 --iou 0.65 --task val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/data/coco128.yaml, weights=['yolov5m.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v7.0-411-gf4d8a84c Python-3.11.11 torch-2.6.0+cu124 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients, 48.9 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/datas\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        128        929      0.735      0.694      0.773      0.553\n",
      "Speed: 0.8ms pre-process, 156.7ms inference, 1.9ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp79\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# For YOLOv5m\n",
    "!python val.py --weights yolov5m.pt --data coco128.yaml --img 640 --iou 0.65 --task val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/data/coco128.yaml, weights=['yolov5l.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v7.0-411-gf4d8a84c Python-3.11.11 torch-2.6.0+cu124 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients, 109.0 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/datas\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        128        929      0.795      0.694      0.811      0.602\n",
      "Speed: 0.9ms pre-process, 294.4ms inference, 2.0ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp80\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# For YOLOv5l\n",
    "!python val.py --weights yolov5l.pt --data coco128.yaml --img 640 --iou 0.65 --task val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/data/coco128.yaml, weights=['yolov5x.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v7.0-411-gf4d8a84c Python-3.11.11 torch-2.6.0+cu124 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5x summary: 444 layers, 86705005 parameters, 0 gradients, 205.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/datas\u001b[0m\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        128        929      0.773      0.753      0.824       0.63\n",
      "Speed: 1.0ms pre-process, 515.2ms inference, 1.7ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/exp81\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# For YOLOv5x\n",
    "!python val.py --weights yolov5x.pt --data coco128.yaml --img 640 --iou 0.65 --task val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roofline Analysis Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===========================================================================\n",
      "Model      Params (M)  Size (MB)   GFLOPs   Utilization (%)   Bound Type\n",
      "===========================================================================\n",
      "yolov5n          1.87       7.12     2.23            17.47     Compute Bound\n",
      "yolov5s          7.23      27.56     8.22            33.61     Compute Bound\n",
      "yolov5m         21.17      80.77    24.44            47.34     Compute Bound\n",
      "yolov5l         46.53     177.51    54.50            54.68     Compute Bound\n",
      "yolov5x         86.71     330.75   102.73            58.30     Compute Bound\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print(\"===========================================================================\")\n",
    "print(\"Model      Params (M)  Size (MB)   GFLOPs   Utilization (%)   Bound Type\")\n",
    "print(\"===========================================================================\")\n",
    "\n",
    "for model_name in models.keys():\n",
    "    params_m = params_dict[model_name]\n",
    "    model_size = model_size_dict[model_name]\n",
    "    gflops = gflops_dict[model_name]\n",
    "    utilization = utilization_dict[model_name]\n",
    "    bound_type = bound_type_dict[model_name]\n",
    "\n",
    "    print(f\"{model_name:<10} {params_m:>10.2f}  {model_size:>9.2f}  {gflops:>7.2f}  \"\n",
    "          f\"{utilization:>15.2f}     {bound_type}\")\n",
    "\n",
    "print(\"===========================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-Layer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_layer_utilization_dict = {}\n",
    "highest_util_layers = {}\n",
    "lowest_util_layers = {}\n",
    "\n",
    "for model_name in models.keys():\n",
    "    model_util = utilization_dict[model_name]\n",
    "    model_total_gflops = gflops_dict[model_name]\n",
    "    per_layer_gflops = per_layer_gflops_dict[model_name]\n",
    "\n",
    "    # Compute per-layer utilization approx.\n",
    "    per_layer_util = {}\n",
    "    for layer, layer_gflops in per_layer_gflops.items():\n",
    "        if layer.strip() == \"\" or layer.strip() in {\"model\", \"model.model\"}:\n",
    "            continue  # Skip root / aggregate layers\n",
    "        layer_util = (layer_gflops / model_total_gflops) * model_util\n",
    "        per_layer_util[layer] = layer_util\n",
    "\n",
    "    per_layer_utilization_dict[model_name] = per_layer_util\n",
    "\n",
    "    # Sort layers\n",
    "    sorted_layers = sorted(per_layer_util.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Save top and bottom 3 layers\n",
    "    highest_util_layers[model_name] = sorted_layers[:3]\n",
    "    lowest_util_layers[model_name] = sorted_layers[-3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================================\n",
      "Per-Layer Utilization Summary\n",
      "===================================================================\n",
      "\n",
      "Model: yolov5n\n",
      "Highest Utilization Layers:\n",
      "    model.model.6                           : 1.95%\n",
      "    model.model.6.m                         : 1.54%\n",
      "    model.model.4                           : 1.43%\n",
      "Lowest Utilization Layers:\n",
      "    model.model.23.cv3.act                  : 0.00%\n",
      "    model.model.23.m.0.cv1.act              : 0.00%\n",
      "    model.model.23.m.0.cv2.act              : 0.00%\n",
      "\n",
      "Model: yolov5s\n",
      "Highest Utilization Layers:\n",
      "    model.model.6                           : 4.07%\n",
      "    model.model.6.m                         : 3.22%\n",
      "    model.model.4                           : 3.00%\n",
      "Lowest Utilization Layers:\n",
      "    model.model.23.cv3.act                  : 0.00%\n",
      "    model.model.23.m.0.cv1.act              : 0.00%\n",
      "    model.model.23.m.0.cv2.act              : 0.00%\n",
      "\n",
      "Model: yolov5m\n",
      "Highest Utilization Layers:\n",
      "    model.model.6                           : 7.77%\n",
      "    model.model.6.m                         : 6.86%\n",
      "    model.model.4                           : 5.48%\n",
      "Lowest Utilization Layers:\n",
      "    model.model.23.m.0.cv2.act              : 0.00%\n",
      "    model.model.23.m.1.cv1.act              : 0.00%\n",
      "    model.model.23.m.1.cv2.act              : 0.00%\n",
      "\n",
      "Model: yolov5l\n",
      "Highest Utilization Layers:\n",
      "    model.model.6                           : 10.31%\n",
      "    model.model.6.m                         : 9.47%\n",
      "    model.model.4                           : 7.15%\n",
      "Lowest Utilization Layers:\n",
      "    model.model.23.m.1.cv2.act              : 0.00%\n",
      "    model.model.23.m.2.cv1.act              : 0.00%\n",
      "    model.model.23.m.2.cv2.act              : 0.00%\n",
      "\n",
      "Model: yolov5x\n",
      "Highest Utilization Layers:\n",
      "    model.model.6                           : 11.90%\n",
      "    model.model.6.m                         : 11.16%\n",
      "    model.model.4                           : 8.18%\n",
      "Lowest Utilization Layers:\n",
      "    model.model.23.m.2.cv2.act              : 0.00%\n",
      "    model.model.23.m.3.cv1.act              : 0.00%\n",
      "    model.model.23.m.3.cv2.act              : 0.00%\n",
      "===================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===================================================================\")\n",
    "print(\"Per-Layer Utilization Summary\")\n",
    "print(\"===================================================================\")\n",
    "\n",
    "for model_name in models.keys():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "    print(\"Highest Utilization Layers:\")\n",
    "    for layer, util in highest_util_layers[model_name]:\n",
    "        print(f\"    {layer:<40}: {util:.2f}%\")\n",
    "\n",
    "    print(\"Lowest Utilization Layers:\")\n",
    "    for layer, util in lowest_util_layers[model_name]:\n",
    "        print(f\"    {layer:<40}: {util:.2f}%\")\n",
    "print(\"===================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cProfile Profiling results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== cProfile for yolov5n ===\n",
      "         9472617 function calls (8915165 primitive calls) in 12.865 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 528 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     6000    1.974    0.000    1.974    0.000 {built-in method torch.conv2d}\n",
      "        1    1.240    1.240    1.240    1.240 {built-in method torch._C._autograd._disable_profiler}\n",
      "        1    1.223    1.223    6.101    6.101 profiler.py:525(_parse_kineto_results)\n",
      "    92800    0.598    0.000    0.616    0.000 profiler_util.py:446(__init__)\n",
      "    79696    0.581    0.000    0.582    0.000 profiler.py:595(<listcomp>)\n",
      "        3    0.435    0.145    0.435    0.145 {built-in method torch._C._autograd.events}\n",
      "    79696    0.424    0.000    0.426    0.000 {built-in method torch._C._autograd.shapes}\n",
      "   207454    0.341    0.000    0.413    0.000 profiler.py:545(_device_memory_usage)\n",
      "     1700    0.271    0.000    0.271    0.000 {built-in method torch.cat}\n",
      "        1    0.270    0.270    0.336    0.336 profiler.py:529(<listcomp>)\n",
      "   574300    0.268    0.000    0.268    0.000 {built-in method torch._C._autograd.device_type}\n",
      "   608201    0.245    0.000    0.245    0.000 {built-in method torch._C._autograd.name}\n",
      "    79696    0.225    0.000    0.227    0.000 {built-in method torch._C._autograd.concrete_inputs}\n",
      "     5700    0.224    0.000    0.224    0.000 {built-in method torch._C._nn.silu_}\n",
      "    92500    0.223    0.000    0.946    0.000 profiler_util.py:674(add)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "=== cProfile for yolov5s ===\n",
      "         9470408 function calls (8913010 primitive calls) in 17.299 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 352 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     6000    4.397    0.001    4.397    0.001 {built-in method torch.conv2d}\n",
      "        1    1.950    1.950    7.543    7.543 profiler.py:525(_parse_kineto_results)\n",
      "   207453    1.736    0.000    1.904    0.000 profiler.py:537(_cpu_memory_usage)\n",
      "        1    1.236    1.236    1.236    1.236 {built-in method torch._C._autograd._disable_profiler}\n",
      "    92797    0.831    0.000    0.848    0.000 profiler_util.py:446(__init__)\n",
      "        3    0.427    0.142    0.427    0.142 {built-in method torch._C._autograd.events}\n",
      "   207453    0.389    0.000    0.481    0.000 profiler.py:545(_device_memory_usage)\n",
      "     5700    0.335    0.000    0.335    0.000 {built-in method torch._C._nn.silu_}\n",
      "     1700    0.332    0.000    0.332    0.000 {built-in method torch.cat}\n",
      "   574298    0.319    0.000    0.319    0.000 {built-in method torch._C._autograd.device_type}\n",
      "   608198    0.261    0.000    0.261    0.000 {built-in method torch._C._autograd.name}\n",
      "   244796    0.243    0.000    0.285    0.000 profiler_util.py:561(cpu_time_total)\n",
      "      300    0.234    0.001    0.234    0.001 {built-in method torch.max_pool2d}\n",
      "    92497    0.224    0.000    0.993    0.000 profiler_util.py:674(add)\n",
      "    92497    0.196    0.000    0.224    0.000 profiler_util.py:317(get_key)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "=== cProfile for yolov5m ===\n",
      "         11995946 function calls (11279556 primitive calls) in 27.075 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 352 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     8200   10.305    0.001   10.305    0.001 {built-in method torch.conv2d}\n",
      "        1    2.141    2.141    9.282    9.282 profiler.py:525(_parse_kineto_results)\n",
      "        1    1.538    1.538    1.538    1.538 {built-in method torch._C._autograd._disable_profiler}\n",
      "        1    1.464    1.464    1.491    1.491 profiler_util.py:742(<listcomp>)\n",
      "   100196    0.826    0.000    0.829    0.000 {built-in method torch._C._autograd.concrete_inputs}\n",
      "   116195    0.604    0.000    0.605    0.000 profiler_util.py:115(<lambda>)\n",
      "     7900    0.593    0.000    0.593    0.000 {built-in method torch._C._nn.silu_}\n",
      "        3    0.556    0.185    0.556    0.185 {built-in method torch._C._autograd.events}\n",
      "   274853    0.508    0.000    0.626    0.000 profiler.py:545(_device_memory_usage)\n",
      "     1700    0.443    0.000    0.443    0.000 {built-in method torch.cat}\n",
      "   750098    0.401    0.000    0.401    0.000 {built-in method torch._C._autograd.device_type}\n",
      "   100196    0.399    0.000    0.400    0.000 profiler.py:595(<listcomp>)\n",
      "      300    0.343    0.001    0.343    0.001 {built-in method torch.max_pool2d}\n",
      "   770596    0.331    0.000    0.331    0.000 {built-in method torch._C._autograd.name}\n",
      "   274853    0.317    0.000    0.535    0.000 profiler.py:537(_cpu_memory_usage)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "=== cProfile for yolov5l ===\n",
      "         14521818 function calls (13646412 primitive calls) in 40.934 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 352 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    10400   20.951    0.002   20.951    0.002 {built-in method torch.conv2d}\n",
      "        1    5.706    5.706   11.024   11.024 profiler.py:525(_parse_kineto_results)\n",
      "        1    1.862    1.862    1.862    1.862 {built-in method torch._C._autograd._disable_profiler}\n",
      "    10100    0.988    0.000    0.988    0.000 {built-in method torch._C._nn.silu_}\n",
      "   342255    0.632    0.000    0.780    0.000 profiler.py:545(_device_memory_usage)\n",
      "        3    0.617    0.206    0.617    0.206 {built-in method torch._C._autograd.events}\n",
      "     1700    0.567    0.000    0.567    0.000 {built-in method torch.cat}\n",
      "   925902    0.498    0.000    0.498    0.000 {built-in method torch._C._autograd.device_type}\n",
      "      300    0.456    0.002    0.456    0.002 {built-in method torch.max_pool2d}\n",
      "   933000    0.399    0.000    0.399    0.000 {built-in method torch._C._autograd.name}\n",
      "   342255    0.390    0.000    0.661    0.000 profiler.py:537(_cpu_memory_usage)\n",
      "   369202    0.368    0.000    0.434    0.000 profiler_util.py:561(cpu_time_total)\n",
      "   139299    0.344    0.000    1.511    0.000 profiler_util.py:674(add)\n",
      "     3300    0.311    0.000   12.723    0.004 common.py:177(forward)\n",
      "   139299    0.303    0.000    0.344    0.000 profiler_util.py:317(get_key)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "=== cProfile for yolov5x ===\n",
      "         17047036 function calls (16012662 primitive calls) in 63.691 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 352 to 15 due to restriction <15>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    12600   38.302    0.003   38.302    0.003 {built-in method torch.conv2d}\n",
      "        1    2.962    2.962   13.364   13.364 profiler.py:525(_parse_kineto_results)\n",
      "        1    2.257    2.257    2.257    2.257 {built-in method torch._C._autograd._disable_profiler}\n",
      "        1    2.116    2.116    2.197    2.197 profiler_util.py:737(__init__)\n",
      "    12300    1.483    0.000    1.483    0.000 {built-in method torch._C._nn.silu_}\n",
      "   162991    1.001    0.000    1.029    0.000 profiler_util.py:446(__init__)\n",
      "   162991    0.849    0.000    0.850    0.000 profiler_util.py:115(<lambda>)\n",
      "   409652    0.757    0.000    0.935    0.000 profiler.py:545(_device_memory_usage)\n",
      "        3    0.733    0.244    0.733    0.244 {built-in method torch._C._autograd.events}\n",
      "     1700    0.707    0.000    0.707    0.000 {built-in method torch.cat}\n",
      "     4400    0.616    0.000   26.525    0.006 common.py:177(forward)\n",
      "  1101696    0.594    0.000    0.594    0.000 {built-in method torch._C._autograd.device_type}\n",
      "      300    0.568    0.002    0.568    0.002 {built-in method torch.max_pool2d}\n",
      "   141196    0.563    0.000    0.565    0.000 profiler.py:595(<listcomp>)\n",
      "   141196    0.548    0.000    0.551    0.000 {built-in method torch._C._autograd.shapes}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for model_name, stats in profile_outputs.items():\n",
    "    print(f\"\\n=== cProfile for {model_name} ===\")\n",
    "    print(stats)\n",
    "    print(\"\\n========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Profiler Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiler for yolov5n:\n",
      "\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::conv2d         0.78%      21.756ms        69.05%        1.923s     320.533us       5.20 Gb           0 b          6000  \n",
      "                aten::convolution         1.02%      28.429ms        68.26%        1.901s     316.907us       5.20 Gb           0 b          6000  \n",
      "               aten::_convolution         1.32%      36.872ms        67.24%        1.873s     312.169us       5.20 Gb           0 b          6000  \n",
      "         aten::mkldnn_convolution        64.30%        1.791s        65.92%        1.836s     306.024us       5.20 Gb           0 b          6000  \n",
      "                        aten::cat         8.40%     233.982ms         9.17%     255.284ms     150.167us       3.16 Gb       3.16 Gb          1700  \n",
      "                      aten::silu_         7.49%     208.716ms         7.49%     208.716ms      36.617us           0 b           0 b          5700  \n",
      "                 aten::max_pool2d         0.04%       1.165ms         4.23%     117.827ms     392.757us      60.55 Mb    -113.28 Mb           300  \n",
      "    aten::max_pool2d_with_indices         4.19%     116.662ms         4.19%     116.662ms     388.872us     175.78 Mb     175.78 Mb           300  \n",
      "                      aten::copy_         3.23%      89.838ms         3.23%      89.838ms      59.892us           0 b           0 b          1500  \n",
      "                 aten::contiguous         0.07%       2.026ms         2.78%      77.372ms     128.953us     996.46 Mb           0 b           600  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.785s\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Profiler for yolov5s:\n",
      "\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::conv2d         0.56%      30.769ms        78.74%        4.325s     720.762us       9.61 Gb           0 b          6000  \n",
      "                aten::convolution         0.70%      38.184ms        78.18%        4.294s     715.634us       9.61 Gb           0 b          6000  \n",
      "               aten::_convolution         0.88%      48.366ms        77.48%        4.256s     709.270us       9.61 Gb           0 b          6000  \n",
      "         aten::mkldnn_convolution        75.26%        4.133s        76.60%        4.207s     701.208us       9.61 Gb           0 b          6000  \n",
      "                        aten::cat         5.24%     287.540ms         5.69%     312.651ms     183.912us       4.72 Gb       4.72 Gb          1700  \n",
      "                      aten::silu_         5.68%     312.137ms         5.68%     312.137ms      54.761us           0 b           0 b          5700  \n",
      "                 aten::max_pool2d         0.03%       1.416ms         4.21%     231.228ms     770.760us     117.97 Mb    -232.81 Mb           300  \n",
      "    aten::max_pool2d_with_indices         4.18%     229.812ms         4.18%     229.812ms     766.041us     351.56 Mb     351.56 Mb           300  \n",
      "                      aten::copy_         1.99%     109.560ms         1.99%     109.560ms      73.040us           0 b           0 b          1500  \n",
      "                 aten::contiguous         0.03%       1.592ms         1.48%      81.107ms     135.179us       1.07 Gb           0 b           600  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.492s\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Profiler for yolov5m:\n",
      "\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::conv2d         0.40%      47.990ms        85.70%       10.195s       1.243ms      17.68 Gb           0 b          8200  \n",
      "                aten::convolution         0.48%      56.711ms        85.30%       10.147s       1.237ms      17.68 Gb           0 b          8200  \n",
      "               aten::_convolution         0.58%      69.066ms        84.82%       10.090s       1.230ms      17.68 Gb           0 b          8200  \n",
      "         aten::mkldnn_convolution        83.27%        9.906s        84.24%       10.021s       1.222ms      17.68 Gb           0 b          8200  \n",
      "                      aten::silu_         4.69%     557.735ms         4.69%     557.735ms      70.599us           0 b           0 b          7900  \n",
      "                        aten::cat         3.31%     394.127ms         3.54%     420.552ms     247.384us       6.29 Gb       6.29 Gb          1700  \n",
      "                 aten::max_pool2d         0.01%       1.513ms         2.86%     340.073ms       1.134ms     175.78 Mb    -351.56 Mb           300  \n",
      "    aten::max_pool2d_with_indices         2.85%     338.560ms         2.85%     338.560ms       1.129ms     527.34 Mb     527.34 Mb           300  \n",
      "                      aten::copy_         0.93%     110.112ms         0.93%     110.112ms      73.408us           0 b           0 b          1500  \n",
      "                        aten::add         0.81%      96.814ms         0.81%      96.814ms      56.949us       2.65 Gb       2.65 Gb          1700  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 11.896s\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Profiler for yolov5l:\n",
      "\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::conv2d         0.29%      68.006ms        89.13%       20.784s       1.998ms      28.19 Gb           0 b         10400  \n",
      "                aten::convolution         0.36%      82.966ms        88.83%       20.716s       1.992ms      28.19 Gb           0 b         10400  \n",
      "               aten::_convolution         0.42%      98.222ms        88.48%       20.633s       1.984ms      28.19 Gb           0 b         10400  \n",
      "         aten::mkldnn_convolution        87.23%       20.343s        88.06%       20.535s       1.975ms      28.19 Gb           0 b         10400  \n",
      "                      aten::silu_         4.01%     934.629ms         4.01%     934.629ms      92.538us           0 b           0 b         10100  \n",
      "                        aten::cat         2.21%     514.412ms         2.33%     542.304ms     319.002us       7.85 Gb       7.85 Gb          1700  \n",
      "                 aten::max_pool2d         0.01%       1.774ms         1.94%     452.797ms       1.509ms     234.38 Mb    -468.75 Mb           300  \n",
      "    aten::max_pool2d_with_indices         1.93%     451.023ms         1.93%     451.023ms       1.503ms     703.12 Mb     703.12 Mb           300  \n",
      "                        aten::add         1.09%     255.093ms         1.09%     255.093ms     106.289us       5.28 Gb       5.28 Gb          2400  \n",
      "                      aten::copy_         0.63%     146.040ms         0.63%     146.040ms      97.360us           0 b           0 b          1500  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 23.320s\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Profiler for yolov5x:\n",
      "\n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::conv2d         0.27%     113.750ms        91.45%       38.062s       3.021ms      41.14 Gb           0 b         12600  \n",
      "                aten::convolution         0.29%     121.178ms        91.18%       37.948s       3.012ms      41.14 Gb           0 b         12600  \n",
      "               aten::_convolution         0.33%     135.526ms        90.89%       37.827s       3.002ms      41.14 Gb           0 b         12600  \n",
      "         aten::mkldnn_convolution        89.65%       37.312s        90.56%       37.691s       2.991ms      41.14 Gb           0 b         12600  \n",
      "                      aten::silu_         3.38%        1.408s         3.38%        1.408s     114.478us           0 b           0 b         12300  \n",
      "                        aten::cat         1.56%     650.724ms         1.63%     679.852ms     399.913us       9.42 Gb       9.42 Gb          1700  \n",
      "                 aten::max_pool2d         0.01%       2.085ms         1.36%     564.146ms       1.880ms     292.97 Mb    -585.94 Mb           300  \n",
      "    aten::max_pool2d_with_indices         1.35%     562.061ms         1.35%     562.061ms       1.874ms     878.91 Mb     878.91 Mb           300  \n",
      "                        aten::add         1.26%     525.184ms         1.26%     525.184ms     169.414us       8.79 Gb       8.79 Gb          3100  \n",
      "                      aten::empty         0.71%     295.738ms         0.71%     295.738ms      11.047us      42.53 Gb      42.53 Gb         26772  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 41.620s\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model_name, prof_table in profiler_tables.items():\n",
    "    print(f\"Profiler for {model_name}:\\n\")\n",
    "    print(prof_table)\n",
    "    print(\"-\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimizing yolov5n with Quantization + ONNX + Batching ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/models/common.py:700: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n",
      "/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/models/yolo.py:101: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
      "Unsupported operator aten::silu_ encountered 57 time(s)\n",
      "Unsupported operator aten::add encountered 10 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::mul encountered 22 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 3 time(s)\n",
      "Unsupported operator aten::pow encountered 3 time(s)\n",
      "/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/models/common.py:700: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n",
      "/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/models/yolo.py:101: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimizing yolov5s with Quantization + ONNX + Batching ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::silu_ encountered 57 time(s)\n",
      "Unsupported operator aten::add encountered 10 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::mul encountered 22 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 3 time(s)\n",
      "Unsupported operator aten::pow encountered 3 time(s)\n",
      "/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/models/common.py:700: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimizing yolov5m with Quantization + ONNX + Batching ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/models/yolo.py:101: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
      "Unsupported operator aten::silu_ encountered 79 time(s)\n",
      "Unsupported operator aten::add encountered 17 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::mul encountered 22 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 3 time(s)\n",
      "Unsupported operator aten::pow encountered 3 time(s)\n",
      "/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/models/common.py:700: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimizing yolov5l with Quantization + ONNX + Batching ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/models/yolo.py:101: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
      "Unsupported operator aten::silu_ encountered 101 time(s)\n",
      "Unsupported operator aten::add encountered 24 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::mul encountered 22 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 3 time(s)\n",
      "Unsupported operator aten::pow encountered 3 time(s)\n",
      "/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/models/common.py:700: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimizing yolov5x with Quantization + ONNX + Batching ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dishapant/Desktop/spp/yolov5_benchmarking_optimization/yolov5/models/yolo.py:101: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
      "Unsupported operator aten::silu_ encountered 123 time(s)\n",
      "Unsupported operator aten::add encountered 31 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
      "Unsupported operator aten::mul encountered 22 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 3 time(s)\n",
      "Unsupported operator aten::pow encountered 3 time(s)\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "batch_size = 4\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n--- Optimizing {model_name} with Quantization + ONNX + Batching ---\")\n",
    "\n",
    "    # 1. Quantize model (Dynamic INT8)\n",
    "    quantized_model = quantize_dynamic(model.to(device).eval(), {torch.nn.Linear}, dtype=torch.qint8)\n",
    "\n",
    "    # 2. Export to ONNX\n",
    "    dummy = torch.randn(1, 3, 640, 640).to(device)\n",
    "    onnx_path = f\"{model_name}_quant.onnx\"\n",
    "    torch.onnx.export(\n",
    "        quantized_model,\n",
    "        dummy,\n",
    "        onnx_path,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        opset_version=12,\n",
    "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # 3. Inference with ONNX Runtime\n",
    "    ort_session = ort.InferenceSession(onnx_path, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "    # Load and batch images\n",
    "    images = []\n",
    "    for img_path in image_files:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        tensor = transform(img).numpy()\n",
    "        images.append(tensor)\n",
    "    all_batches = [images[i:i+batch_size] for i in range(0, len(images), batch_size)]\n",
    "\n",
    "    total_time = 0\n",
    "    for batch in all_batches:\n",
    "        input_batch = np.stack(batch, axis=0).astype(np.float32)  # ONNX uses FP32 input\n",
    "        start = time.time()\n",
    "        _ = ort_session.run(None, {\"input\": input_batch})\n",
    "        end = time.time()\n",
    "        total_time += (end - start)\n",
    "\n",
    "    total_images = len(images)\n",
    "    avg_latency = (total_time / total_images) * 1000\n",
    "    avg_fps = total_images / total_time\n",
    "\n",
    "    # Model summary\n",
    "    info = summary(\n",
    "        model,\n",
    "        input_size=(1, 3, 640, 640),\n",
    "        dtypes=[torch.float],\n",
    "        device=device,\n",
    "        verbose=0\n",
    "    )\n",
    "    total_params = info.total_params\n",
    "    params_m = total_params / 1e6\n",
    "    model_size_mb = total_params * 4 / (1024 ** 2)\n",
    "\n",
    "    # FLOPs\n",
    "    input_tensor = torch.randn(1, 3, 640, 640).to(device)\n",
    "    flops = FlopCountAnalysis(model, input_tensor)\n",
    "    total_flops = flops.total()\n",
    "    gflops = total_flops / 1e9\n",
    "\n",
    "    # Utilization\n",
    "    actual_gflops_per_second = gflops / (avg_latency / 1000)\n",
    "    utilization = (actual_gflops_per_second / PEAK_GFLOPS) * 100\n",
    "\n",
    "    # OI (Operational Intensity)\n",
    "    input_size_bytes = 3 * 640 * 640 * 4  # FP32 = 4 bytes\n",
    "    activation_estimate = input_size_bytes * 3\n",
    "    memory_accessed = total_params * 4 + activation_estimate  # INT8 model, but input is FP32\n",
    "    oi = total_flops / memory_accessed\n",
    "    peak_oi = PEAK_GFLOPS / PEAK_BANDWIDTH\n",
    "    bound_type = \"Compute Bound\" if oi > peak_oi else \"Memory Bound\"\n",
    "\n",
    "    results[model_name] = {\n",
    "        \"Latency (ms)\": avg_latency,\n",
    "        \"FPS\": avg_fps,\n",
    "        \"Params (M)\": params_m,\n",
    "        \"Model Size (MB)\": model_size_mb,\n",
    "        \"GFLOPs\": gflops,\n",
    "        \"Utilization (%)\": utilization,\n",
    "        \"Operational Intensity\": oi,\n",
    "        \"Bound Type\": bound_type,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Model        Latency (ms)        FPS   Params (M)    Size (MB)     GFLOPs    Utilization (%)     Bound Type\n",
      "====================================================================================================\n",
      "yolov5n             20.32      49.22         1.87         7.12       2.23              26.83  Compute Bound\n",
      "yolov5s             68.20      14.66         7.23        27.56       8.22              29.39  Compute Bound\n",
      "yolov5m            130.23       7.68        21.17        80.77      24.44              45.77  Compute Bound\n",
      "yolov5l            254.88       3.92        46.53       177.51      54.50              52.15  Compute Bound\n",
      "yolov5x            449.10       2.23        86.71       330.75     102.73              55.79  Compute Bound\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 100)\n",
    "print(f\"{'Model':<10} {'Latency (ms)':>14} {'FPS':>10} {'Params (M)':>12} {'Size (MB)':>12} {'GFLOPs':>10} {'Utilization (%)':>18} {'Bound Type':>14}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for model_name, stats in results.items():\n",
    "    print(f\"{model_name:<10} \"\n",
    "          f\"{stats['Latency (ms)']:>14.2f} \"\n",
    "          f\"{stats['FPS']:>10.2f} \"\n",
    "          f\"{stats['Params (M)']:>12.2f} \"\n",
    "          f\"{stats['Model Size (MB)']:>12.2f} \"\n",
    "          f\"{stats['GFLOPs']:>10.2f} \"\n",
    "          f\"{stats['Utilization (%)']:>18.2f} \"\n",
    "          f\"{stats['Bound Type']:>14}\")\n",
    "\n",
    "print(\"=\" * 100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
